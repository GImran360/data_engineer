# data_engineer

<img width="1806" height="666" alt="image" src="https://github.com/user-attachments/assets/73c310db-d31d-440e-b484-acaa65de06d7" />
<img width="487" height="172" alt="image" src="https://github.com/user-attachments/assets/33e1762a-2406-4de7-9462-dd6ee37db289" />
<img width="1020" height="119" alt="image" src="https://github.com/user-attachments/assets/c53ebf50-ceae-4f43-bafb-1d77c20fd953" />
<img width="1509" height="944" alt="image" src="https://github.com/user-attachments/assets/cd511e10-aefa-4587-b18d-b9f97f032bb0" />
<img width="1131" height="624" alt="image" src="https://github.com/user-attachments/assets/256249f2-c747-44ff-b185-5ca51bdedb93" />
<img width="1875" height="1040" alt="image" src="https://github.com/user-attachments/assets/488aa1ff-4686-424b-a227-eff8800cb21f" />
<img width="1715" height="1040" alt="image" src="https://github.com/user-attachments/assets/9be26533-7570-4c3e-9ce4-7dc646efeae7" />
<img width="883" height="275" alt="image" src="https://github.com/user-attachments/assets/7749479a-b6b8-4239-a1e5-1dec9b95b6e2" />
<img width="877" height="514" alt="image" src="https://github.com/user-attachments/assets/3a129a99-fa75-49ab-aff1-18c79934e2fc" />
<img width="640" height="142" alt="image" src="https://github.com/user-attachments/assets/611a6fe0-3ba0-4ea1-9ec4-02cb331084ef" />
<img width="1840" height="598" alt="image" src="https://github.com/user-attachments/assets/01aa5b84-10b2-4b4b-9338-3f3fb16c0331" />
<img width="1845" height="846" alt="image" src="https://github.com/user-attachments/assets/db75c219-4a95-4d26-9f18-ce0d096c0610" />
<img width="1891" height="987" alt="image" src="https://github.com/user-attachments/assets/151d4de4-0835-4f49-b5ce-10e6bc1b25eb" />
<img width="1651" height="894" alt="image" src="https://github.com/user-attachments/assets/62cfc9fd-65a4-4854-ad0f-7d1b1a6a76f4" />
<img width="1499" height="591" alt="image" src="https://github.com/user-attachments/assets/b1504ea0-2841-4e2f-9588-b33cdbcd153c" />
<img width="741" height="609" alt="image" src="https://github.com/user-attachments/assets/c0cc50ec-4418-461b-b159-6284a63aa579" />
<img width="1900" height="954" alt="image" src="https://github.com/user-attachments/assets/aa58b7bd-4621-4f38-b14b-eba2a4c05ca3" />
<img width="1523" height="662" alt="image" src="https://github.com/user-attachments/assets/50edc110-46d4-4567-8000-080817113a19" />
<img width="800" height="602" alt="image" src="https://github.com/user-attachments/assets/ba021069-4c44-4620-8d37-19f6a037b666" />
<img width="1194" height="110" alt="image" src="https://github.com/user-attachments/assets/71070c73-2cc4-4b66-80ac-d3f91c618150" />
<img width="1187" height="103" alt="image" src="https://github.com/user-attachments/assets/ae59fade-01c8-409c-abee-4c77b4f32fc2" />
<img width="714" height="667" alt="image" src="https://github.com/user-attachments/assets/7e57b212-9366-4a72-b93b-cbcd4271e875" />
<img width="1670" height="706" alt="image" src="https://github.com/user-attachments/assets/24983bc3-d4b9-4f50-a5dc-0b47f145efb8" />
<img width="1224" height="430" alt="image" src="https://github.com/user-attachments/assets/8e13c9c9-850b-4195-be8d-a6987bb21d25" />
<img width="1819" height="768" alt="image" src="https://github.com/user-attachments/assets/e712c17f-876c-4ec3-bc48-169047139732" />
<img width="853" height="490" alt="image" src="https://github.com/user-attachments/assets/20b22547-22ca-4db9-aeab-e1df2f77da51" />
<img width="1130" height="581" alt="image" src="https://github.com/user-attachments/assets/7d999585-0013-41d8-b1e3-ee1049b4bdb3" />
<img width="1863" height="605" alt="image" src="https://github.com/user-attachments/assets/b929e740-8908-45a4-9f3e-458859970d51" />
<img width="1919" height="960" alt="image" src="https://github.com/user-attachments/assets/c389c4c5-2ad4-4651-90e9-4d94421b83b9" />
<img width="1867" height="967" alt="image" src="https://github.com/user-attachments/assets/bec85a89-1c23-4100-ac6f-ad86485b64e1" />
Today's class :  Installation 
======================================================
Virtual Box   - it is used to launch virtual machines  (Visual studo c++)  - Install 
Redhat - Linux 



Linux Commands 
=======================================================

pwd : it is used to know current path.

ls : it is used to know list of files and folders in current directory.

ls -ltr : it is used to know list of file and folder in current directory and it will show the file sizes and file permissions

_    rwxrwxrwx 
d    rwxrwxrwx   

1 + 9       = 10  


d    		rwx 	rwx     rwx 

Folder      User   group  others


User/group/ others
===========================
r (Read)     ->   4  
w (write)    ->   2
x (execute)  ->   1
-----------------------
				  7
				  
mkdir hari : It is used to create folder/directory in linux
				  				  
folder : Hari (default - drwxrwxr-x)

d    		rwx    ---    	---
folder 		user   group  	others 

chmod  700 Hari  : It is used to give the file and folder permissions.

cd --- It is used to change the directory
	child foler : cd hari 
	parent folder : cd ..

File create :
	nano file.txt 
	cat > file1.txt 
	
cat file.txt : this command is used to show the data in file.

remove :
	rm   : it is used to delete file.
	rm -r : it is used to delete all files and folders in current directory.
	
	
2023-04-06 
============================

cp source target  : It is used to copy file from one location/folder to another location/folder.

mv source target  : 
	1. it is used to move the file from one directory to another directory.
	2. We can rename the file.

zip ravi.zip ravi.txt  : it is used to zip the file. 

ifconfig : It is used to know system ip address.

chmod 777 file.txt : to change file/directory permissions.
chgrp honey file.txt : It is used to change the group on file or directory.

chown jagan file.txt : It is used to change the owner name on file or directory.


Doubts  : 
====================

3 versions :


Hadoop 1.x
====================
 
	HDFS : (hadoop distributed file system) : Data Stroage 
	MapReduce : Data Processing + Resource management


Hadoop 2.x :
====================

	HDFS : Data storage 
	MapReduce : Data Processing.
	Yarn (Yet another resource negotiator) : Resource Manager
	

Hadoop(Cluster) Architecture : hadoop is a master and slave architecture.
===============================
Cluster : more than 1 computer and it is ingreated with remaining all computers.


2 machines = 2 Node cluster.
4 Machines = 4 Node cluster.
10 Machines = 10 Node cluster.
100 Machines = 100 Node cluster.

Features of Hadoop : 
========================
	1. Reliabe  : Handle failure.(Data Replication)
	2. Flexible : Add more systems with out down time.
	3. Economical  : Commericial H/W used in cheap
	4. Stable : Reliabe + consistency of the system. It will work with out any up expected error/failures.
	
	HDFS  :
================================
1. It is designed to store and manage large datasets/ files across cluster.
2. It is core component of the hadoop eco system.
3. It is responsible for providing reliable and fault tolarance storage for big data applications.

Components : 
============	
	Name Node : Name Node stores only metadata information
	
	Data Node  : Data Node stores actual data.
	
	Secondary Name Node : In hadoop, the scondary name node is a helper node for the name node.
	
	fsimage : It is file that contains a snapshot of metadata information stored in the namenode.
	
	edit logs : After latest fsimage snapshot, Changes infromation is stored in edit logs.
	
	
	
Diffrence between data and metadata :
==================================================
image.jpg  = 10 MB


Atual data size is 10 MB 
Metadata  : data about data. 
			file_name : image 
			file_type : JPG
			file_size : 10mb
			storage_location : /pictures/image.jpg

Tomorrow session : 
======================



blocks : Any kind of data is stored in block wise in HDFS. (hdfs-site.xml)
=============
	Hard disk : 4KB 
	HDFS  : 128 mb  
	
	Image.jpg : 10MB 
	
	
			
Replication :   property in configuration file : 3. It is possible to increase or decrease. (hdfs-site.xml)
===============


Heart beats :
=================
1. Data node sends heartbeats to NameNode every 3 seconds.Then NameNode knows that data nodes are available.


We can connect HDFS storage two ways :
-----------------------------------
1. using cli hdfs commands.
2. web browser.

HDFS Commands :
====================

ls 
hdfs dfs -ls /user/cloudera/

mkdir honey 
hdfs dfs -mkdir /user/cloudera/honey

rm -r honey
hdfs dfs -rm -r /user/cloudera/honey

chmod 777 honey 
hdfs dfs -chmod 777 /user/cloudera/honey

Copy :
cp linux_source_location linux_target_location

hdfs dfs -put local_file_system(lfs) hadoop_distributed_file_system(hdfs) 
hdfs dfs -copyFromLocal local_file_system(lfs) hadoop_distributed_file_system(hdfs)

hdfs dfs -get hdfs_location lfs_location
hdfs dfs -copyToLocal hdfs_location lfs_location

hdfs location -> hdfs another location.

hdfs dfs -cp /user/cloudera/test_hdfs.txt  /user/
hdfs dfs -mv /user/test_hdfs.txt /user/hdfs/

file delete :
hdfs dfs -rm /user/cloudera/test_hdfs.txt 

hdfs dfs -cat /user/cloudera/test_hdfs.txt

hdfs dfs -chgrp hadoop /user/cloudera/test_hdfs.txt

hdfs dfs -chown mapred /user/cloudera/test_hdfs.txt

<img width="1594" height="635" alt="image" src="https://github.com/user-attachments/assets/e35f1000-3872-431e-9a2e-94926e2837c7" />
<img width="1810" height="601" alt="image" src="https://github.com/user-attachments/assets/4dfa939e-a69b-4073-88aa-2c89d435f87b" />
<img width="1779" height="954" alt="image" src="https://github.com/user-attachments/assets/972355e3-4ec7-4d9f-9ea4-cdb312183f60" />
